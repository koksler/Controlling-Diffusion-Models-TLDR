[[06_LoRA]]
# ControlNET

Диффузионные модели непредсказуемые, и это их главное преимущество и недостаток (wowzers). Это разнообразие и отсутствие контроля. И хорошо то, что второе придумали как пресекать.

Авторы ControlNet (Лвмин Чжан и Ману Бхаргава) предложили простую идею. Вместо одного ввода (текстовый промпт), даём модели два: креативный промпт (что рисовать) и структурный промпт (куда рисовать).

Модель должна выполнить оба условия: нарисовать то, что в промпте, но вписать это в заданную схему.

1. Мы берем огромную, обученную модель U-Net и полностью ее замораживаем. Все ее миллиарды весов остаются неизменными. Она хранит в себе все знания о том, как рисовать красивые картинки.
2. Далее создаем точную копию этой модели, но делаем ее очень легкой и обучаемой. Этот близнец будет учиться читать карты контроля.
3. Процесс генерации:
    - Наш промпт и зашумленное изображение идут в обоих близнецов.
    - А вот карта контроля (например, скелет позы) идет на вход только обучаемому близнецу.
    - Обучаемый близнец учится одной-единственной вещи: генерировать "подсказки" для своего старшего брата. Он отсылает модели требования "где и что" должно находиться.
    - Эти "подсказки" от обучаемого близнеца добавляются к результатам работы основного, замороженного близнеца на каждом шаге.
    - Таким образом, основная модель все еще рисует так, как умеет, но ее процесс 
    - постоянно и мягко корректируется в соответствии со структурной схемой.

<img width="658" height="303" alt="image" src="https://github.com/user-attachments/assets/434281c7-3921-434b-a883-94c43ff901d9" />

В итоге вторая модель генерирует "лайнарт" или карту углов какого-то изображения (или она заливается уже готовая) и это влияет на итоговую генерацию

![Control_NET](/visual/Влияние_ControlNET)

Как тут видно, нейронка взяла констрастные части изображения (Зелёная кожа Гекса и фон) и перевела их в паттерны распространения космической дымки.
